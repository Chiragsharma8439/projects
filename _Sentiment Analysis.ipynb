{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db57462d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a1797",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is a subset of Artificial Intelligence where we aim to train computers to understand human languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697cff5",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ee071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9981452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\ASUS\\Downloads\\archive (12)\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3abc830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d9190",
   "metadata": {},
   "source": [
    "#### Sort the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd7e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  As a longtime admirer of the 2001 film \"Moulin...  positive\n",
      "1  I'm a writer working at home and Diagnosis Mur...  positive\n",
      "2  I've read one comment which labeled this film ...  positive\n",
      "3  This film is enjoyable if you like poverty row...  negative\n",
      "4  In the opening scene, the eye patch wearing de...  positive\n"
     ]
    }
   ],
   "source": [
    "# Filter 2000 'positive' sentiment rows\n",
    "positive_samples = df[df['sentiment'] == 'positive'].sample(n=2000, random_state=1)\n",
    "\n",
    "# Filter 2000 'negative' sentiment rows\n",
    "negative_samples = df[df['sentiment'] == 'negative'].sample(n=2000, random_state=1)\n",
    "\n",
    "# Combine the two datasets\n",
    "final_samples = pd.concat([positive_samples, negative_samples])\n",
    "\n",
    "# Shuffle the combined dataset if necessary\n",
    "final_samples = final_samples.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Save or return the reduced dataset\n",
    "final_samples.to_csv('reduced_dataset.csv', index=False)\n",
    "\n",
    "# Print out to check\n",
    "print(final_samples.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42371d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86db184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de5f38",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7891e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "df[\"review\"] = df[\"review\"].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c564c",
   "metadata": {},
   "source": [
    "### Data split into traning and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb7ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df[\"review\"])\n",
    "y = np.array(df[\"sentiment\"])\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d19e7",
   "metadata": {},
   "source": [
    "# Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07a5a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "model = PassiveAggressiveClassifier()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e8d96",
   "metadata": {},
   "source": [
    "# Model Testing | prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fcc7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text: i like this movie\n",
      "['positive']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f98b867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
